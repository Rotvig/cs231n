\section{Deep Neural Net - RegularNet}
\todo{Starten på dette afsnit virker lidt underligt?}composed exclusively of regular and strided convolutional layers. While this architecture works well for relatively shallow networks, it becomes increasingly more difficult to train as the network depth increases.

Regular networks are a combination of the two standard forms of neural networks, the fully connected neural network and the convolution neural network.

\subsection{Fully Connected Neural Networks (FCNN)}
A neural network consist of an input layer, some hidden layers and an output layer. The input layer is an image, and it is targeted for feature extraction and classification in the hidden layers and output layer. Every pixel in the image is connected to every neuron in the first hidden layer of the neural network as seen in figure \re{fig:RegularFCNN}.    
Each hidden layer is an array of neurons, with each neuron normally consisting of a weight, some activation function and a regulation function. Each pixel value is weighted, activated in an activation function and regularized. Most often ReLU or Leaky ReLU are used as activation function to zero out negative values. The activation function provides a non-linear relationship within the data points to provide better feature extractions. Each neuron in the second hidden layer is supplied with the output of all the neurons in the previous layer and the procedure is repeated until the last hidden layer. The output layer consist of a loss function which is often either a Softmax loss function or a support vector machine loss function. The amount of loss functions in the output layer is equal to the amount of classification categories the image can be classified as.

An image is forwarded through the neural network, and the loss functions provides the misclassification percentage of the image. This error, or loss in accuracy, is send back through the neural network and a gradient for each neuron is found. This process is repeated for, normally, an integer amount of images, batch size, and for each backward propagation the gradient is saved. After a batch of images all the gradients saved for an individual neuron are average and from this value the neural network response to the back propagation. The weights are updated depending on the averaged gradients and this procedure can be done in different ways. The most modern update method is called ADAM, and it is trying to reduce the loss result by changing the weights regarding to the gradients. ADAM will decide the amount of change the weights must have in relation to the gradients, while the regularization step decides the relationship of the change between the weights. ADAM defines the maximum change to a single weight, while the regularization defines the distribution of change over all weights related to the maximum defined change.

\myFigure{RegularNet_FCNN.png}{Fully Connected Neural Network Architecture \citep{RegularNET_FCNN}}{fig:RegularFCNN}{0.5}
\FloatBarrier

\subsection{Convolutional Neural Networks (CNN)}

The main difference between the FCNN and CNN is the FCNN is providing every input pixel to every neuron between each layer, while the CNN is only connecting the neurons to regions of interest of the image, also known as receptive fields. Each receptive field is dotted together with a feature map which provides a single pixel output.

The input layer is an image, while the next layer consist of weighted feature maps, an activation function and a regulation function. Each feature map consist of three spatial dimensions. One spatial dimension of the feature map is convolved with one spatial dimension of the image. The result of dot products for the image pixel at one receptive field with the feature map provides a value for the receptive field. Convolving the input image of \todo{Hvad er N og M i denne sammenhæng, forklar gerne i teksten hvad det er?} $NxMx3$ with X feature maps of 3x3x3 provides X new images with a dimension determine by the striding distance for the convolution as seen in figure \ref{fig:RegularStrinding}.

\myFigure{RegularNET_Strinding.png}{Convolutional Neural Network feature map striding example \citep{RegularNET_Strinding}}{fig:RegularStrinding}{0.5}
\FloatBarrier

Pooling layers are put in between layers at convenient places, to minimize variable count and training time for the neural network. This is typical done by increasing filter strides or by max pooling. Max pooling is choosing the highest pixel value in a spatial dimension of the image and compressing the images to only the chosen max pooling values, as seen in figure \ref{fig:RegularCNN}. It will not always be possible to have the desired stride unit distance in the image, so an extra layer of zeros are padded on to the image to make sure the image is filtered with the correct feature map size and stride unit distance. One zero padding layer and an 3x3 feature map will return an image with the same size as the input image.

\myFigure{RegularNet_CVNN.png}{Convolutional Neural Network Architecture \citep{RegularNET_CVNN}}{fig:RegularCVNN}{0.5}
\FloatBarrier