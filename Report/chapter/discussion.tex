\chapter{Discussion}
\label{chp:discussion}

\subsection{Implementation Experience}

The main purpose of this project was to compare the three neural networks of a regular neural network, a residual neural network and a dense neural network. The different networks have different depth and different architecture in the form of skip connections. The first experience was the different time and memory required to train the models on the small images from the CIFAR-10 data set. On a nvidia geforce gtx 960 2gb Graphics Processing Unit, it took just below two hours to train the RegularNet model, two hours and 45 minutes to train the ResNet model, while with the DensNet model it was not possible to train the model at all, due to memory shortage in the 2gb RAM. Even when batch size was reduced to 1 image per input the memory still was exhausted quickly. Training on a 16gb CPU all night resulted in a trained model from the DensNet top keep the process in the project. It was definitely a eye opener to understand the amount of data being processed by the neural network.
Splitting the training up into more sessions would probably to preferable for a design build from the button up and running it with a GPU, but this was not the scope of this project and so the CPU solution was preferred. The same scenario happened when the images had to be rotated and tested in the model, just in this case, all the models were not able to run on the GPU. All rotational results were made with a slower solution by using the CPU, but it was possible to do so with the extra memory.

\subsection{Test Accuracy}

\myFigure{Test_Error_Plots.png}{Fully Connected Neural Network Architecture \citep{Test_Error_Plots}}{fig:TestErrorPlots}{0.5}
\FloatBarrier

The three models were tested to see which one would get the best test accuracy trained and tested on the original CIFAR-10 data set. All models had a 20000 steps run and the same data folds to train on. The batchsize was 64 images randomly chosen from one fold at a time, so to neglect the randomness factor in the model accuracy, the training was made over 26 epochs. Looking at the graph of figure fig:TestErrorPlots, it shows all the test errors have flattened out when the training was done. As expected the RegularNet had the slowest assent to the stable test error percentage at approximately 1300 steps or approximately 16.5 epochs of trained data. ResNet and DensNet both settles their test error percentage around 75 steps or 9.5 epochs, but DensNet seems to be more controlled and with less deviation, while the ResNet more variate in the increasing accuracy. The highest test accuracy of the three models was found by the DensNet model with an accuracy of 0.88 percentage of test images being correctly categorized. Next, the ResNet model had a best test accuracy of 0.874 of the images categorized correctly. While five percentage might seem like a small change on paper, it can mean be a huge difference in big data analysis. The lowest ranking of the models was the RegularNet with a highest test accuracy of 0.867, but it is still rather close to the other two models.

An extra two percentages can sometimes be found by using model ensemble, but it was not in the scope of this project to optimize the models, but simply to compare the results.

\subsection{Feature Invariance}

The DensNet seems the best model in both speed, stability and test accuracy, but how robust is it? For this question feature invariance was tested, and it provides us with the model response from each model to rotated images. The models behave differently to the categories being rotated. For some categories the 90, 180 and 270 degree angle rotation images are being classified well compared to the other rotational angles, while other categories these angles are valleys in the test accuracy function with respect to rotation. The biggest surprise of the project is the test accuracy when only applying images of one category for testing. Only one category, the automobile, scored a test accuracy above and just above 50\%, while testing the models on images scrambled amongst all categories the test accuracy was for each model above 80\% accuracy.

The three models all have the same problems with rotation as seen in figure ???. Each model increases around 90, 180, 270 degrees, and this due to the behavior of the convolutional networks and the pooling layers. If the network is deep enough it will at some point have dotted the strongest clusters in the pixels together finding the relationship in the data still even though the image is rotated. From visualization reference_to_article_Visualization_And_Understanding, it is possible to see that the rotation has higher effect on the top "spatial smallest" layers than the button ones.

\myFigure{Scrambled Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using Scrambled Images  \citep{Scrambled Images}}{fig:Scrambled Images}{0.5}
\FloatBarrier

In the category 0, the models are trying to detect an airplane. From this plot is estimated to be RegularNet, ResNet and DensNet in the respected order to be chosen for a model. This is counter productive from the previous subchapters, so this behavior is an interesting behavior.

\myFigure{Airplane Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using Airplane Images  \citep{Airplane Images}}{fig:Airplane Images}{0.5}
\FloatBarrier

In the category 1, the models are trying to detect an Automobile. From this plot is estimated to be RegularNet, DensNet and ResNet in the respected order to be chosen for a model. DensNet scores highest in the original image position, but this still proves to be less tolerant for rotation variance. 

\myFigure{Automobile Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using Automobile Images  \citep{Automobile Images}}{fig:Automobile Images}{0.5}
\FloatBarrier 

In the category 2, the models are trying to detect an Birds. From this plot is estimated to be ResNet, DensNet and RegularNet in the respected order to be chosen for a model. DensNet scores the highest peaks along the function, but ResNet have a better average accuracy with respect to rotation in the images. 

\myFigure{Birds Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using Birds Images  \citep{Birds Images}}{fig:Birds Images}{0.5}
\FloatBarrier 

In the category 3, the models are trying to detect an Cats. From this plot is estimated to be RegularNet, DensNet and ResNet in the respected order to be chosen for a model. DensNet scores highest in the original image position, but this still proves to be less tolerant for rotation variance. 

\myFigure{Cats Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using Cats Images  \citep{Cats Images}}{fig:Cats Images}{0.5}
\FloatBarrier 

In the category 4, the models are trying to detect an Deer. From this plot is estimated to be ResNet, DensNet and RegularNet in the respected order to be chosen for a model. 

\myFigure{Deer Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using Deer Images  \citep{Deer Images}}{fig:Deer Images}{0.5}
\FloatBarrier 

In the category 5, the models are trying to detect an Dog. From this plot is estimated to be ResNet, RegularNet and DensNet in the respected order to be chosen for a model.

\myFigure{Dog Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using Dog Images  \citep{Dog Images}}{fig:Dog Images}{0.5}
\FloatBarrier 

In the category 6, the models are trying to detect an frog. From this plot is estimated to be DensNet, RegularNet and ResNet in the respected order to be chosen for a model. 

\myFigure{frog Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using frog Images  \citep{frog Images}}{fig:frog Images}{0.5}
\FloatBarrier 

In the category 7, the models are trying to detect an horse. From this plot is estimated to be DensNet, RegularNet and ResNet in the respected order to be chosen for a model.

\myFigure{horse Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using horse Images  \citep{horse Images}}{fig:horse Images}{0.5}
\FloatBarrier 

In the category 8, the models are trying to detect an ship. From this plot is estimated to be DensNet, RegularNet and ResNet in the respected order to be chosen for a model. 

\myFigure{ship Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using ship Images  \citep{ship Images}}{fig:ship Images}{0.5}
\FloatBarrier 

In the category 9, the models are trying to detect an Dog. From this plot is estimated to be DensNet, ResNet and RegularNet in the respected order to be chosen for a model. 

\myFigure{truck Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using truck Images  \citep{truck Images}}{fig:truck Images}{0.5}
\FloatBarrier

Grading the models with 2 points for a best category model, 1 point for second best category model and 0 for the worst category model gives the following results:
DenseNet   = 12 points out of 20 possible\\
RegularNet = 10 points out of 20 possible\\
ResNet     = 08 points out of 20 possible\\

The subjective best model over all rotational angles is for
(0) An Airplane   = RegularNet\\
(1) An Automobile = RegularNet\\
(2) A Bird        = ResNet\\ 
(3) A Cat         = RegularNet\\
(4) A Deer        = ResNet\\
(5) A Dog         = ResNet\\
(6) A Frog        = DensNet\\
(7) A Horse       = DensNet\\
(8) A Ship        = DensNet\\
(9) A Truck       = DensNet\\

Finally all categories are plotted on the same plot to show the models invariance to rotation across all categories.
