\chapter{Discussion}
\label{chp:discussion}

\subsection{Implementation Experience}

The main purpose of this project was to compare the three neural networks a deep neural network, a deep residual network and a densely connected convolutional network. The different networks have different depth and different architecture. The first experience was the different time and memory required to train the models on the small images from the CIFAR-10 data set. On a nvidia geforce gtx 960 2gb Graphics Processing Unit, training time was about two hours to train the RegularNet, two hours and 45 minutes to train the ResNet, while for the DenseNet it was not possible to train the model at all, due to memory shortage in the 2gb RAM. Training on a 16gb CPU all night resulted in a trained model from the DenseNet.

A bug was discovered in the used implementation from the github repository TF-Tutorials\footnote{\url{https://github.com/awjuliani/TF-Tutorials}}. The bug was found in the preparation of the images before the training of the model. The bug was in the reshaping of the images, which resulted in wrong images. This affected the classification of the test images, and by correcting this bug, better classification results where achieved.
\newpage
\subsection{Test Accuracy}

\myFigure{Summarized_TestError.png}{Test error point measured after training the model with 640 random images and repeated until all 20000 steps had been trained. Left: DenseNet testerror curve, Right: Regular testerror curve, Bottom: ResNet testerror curve.}{fig:SummarizedTestError}{1}
\FloatBarrier

The three networks were tested to see which one would get the best test accuracy trained and tested on the original CIFAR-10 data set. All models had a 20.000 steps run and the same data folds to train on. The batch size was 64 images randomly chosen from one fold at a time, so to neglect the randomness factor in the model accuracy, the training was made over 26 epochs. In the graph of Figure \ref{fig:SummarizedTestError} it is seen that all the test errors have flattened out when the training was done. As expected the RegularNet had the slowest ascend to the stable test error percentage at approximately 1.300 steps or approximately 16.5 epochs of trained data. ResNet and DenseNet both settles their test error percentage around 75 steps or 9.5 epochs, but DenseNet seems to have less deviation, while the ResNet variates in the increasing accuracy. The highest test accuracy of the three models was found by the DenseNet model with an accuracy of 88 percentage. Next the ResNet model had a best test accuracy of 87.4 percentage. While the 0.6 percentage might seem like a small change, it can be a huge difference in big data analysis. The lowest ranking of the models was the RegularNet with a best test accuracy of 86.7 percentage.

\subsection{Feature Invariance}

Feature invariance was tested, and it provides the model response from each model to the rotated images. The models behave differently to the images being rotated. For some labels the 90, 180 and 270 degree angle rotation of the images are being classified well compared to the other angles. The biggest surprise of the project is the test accuracy when only applying images of one label for testing. Only the automobile label scored a test accuracy above 50\%. The test of the models on scrambled images across all labels gave a test accuracy for each model above 80\% accuracy.

The three neural networks, all have the same problems with rotation as seen in Figure \ref{fig:ScrambleImages} 

\myFigure{Scrambled_Images.png}{Test Accuracy for a DensNet, ResNet and RegularNet model using Scrambled Images. Left: DenseNet, Right: RegularNet, Bottom: ResNet}{fig:ScrambleImages}{1}
\FloatBarrier

In table \ref{table:results} the networks has been ranked from best to worst in classifying the different labels. 

\begin{table}[]
	\centering
	\caption{Table consisting of the networks ranked in order from best to worst in classifying rotation specific labels}
	\label{table:results}
	\begin{tabular}{|l|l|}
		\hline
		Label          & Network (Order: Best to worst) \\ \hline
		0 (Airplane)   & RegularNet - ResNet - DenseNet \\ \hline
		1 (Automobile) & RegularNet - DenseNet - ResNet \\ \hline
		2 (Bird)       & DenseNet - ResNet - RegularNet \\ \hline
		3 (Cat)        & DenseNet - ResNet- RegularNet  \\ \hline
		4 (Deer)       & DenseNet - RegularNet - ResNet \\ \hline
		5 (Dog)        & DenseNet - ResNet - RegularNet \\ \hline
		6 (Frog)       & RegularNet - DenseNet - ResNet \\ \hline
		7 (Horse)      & DenseNet - RegularNet - ResNet \\ \hline
		8 (Ship)       & DenseNet - ResNet - RegularNet \\ \hline
		9 (Truck)      & RegularNet - DenseNet - Resnet \\ \hline
	\end{tabular}
\end{table}
\FloatBarrier

Grading the models with 2 points for a best category model, 1 point for second best category model and 0 for the worst category model gives the following results:\\
DenseNet   = 15 points out of 20 possible\\
RegularNet = 10 points out of 20 possible\\
ResNet     = 05 points out of 20 possible\\

In table \ref{table:falseclasReg}, \ref{table:falseclasRes} and \ref{table:falseclas} from chapter \ref{chp:results}, it can be seen that images of ships are the ones with highest misclassification rate, with around 12\% misclassification rate across the three networks.  Another label with high misclassification rate is the truck label. The labels with the lowest misclassification rate is the frog and the dog, meaning that these were the ones that the networks were best at classifying, despite of the rotations. For the RegularNet the frog has a misclassification rate of 7.8\%. For DenseNet and ResNet the dog has the lowest misclassification rate, around 8.37\% for both networks, while the frog has a misclassification rate being just slighly above this.

In chapter \ref{chp:results} on figure \ref{fig:colReg}, \ref{fig:colRes} and \ref{fig:colDense} it can be seen that the automobile images starts out with the highest accuracy, when not rotated. After rotating the automobile images the accuracy drops drastically to around 10\% accuracy. It can also be seen that the accuracy for the frog images starts out around 30\%, but the curve for the accuracy never drops below 10\%. The curve of the accuracy for rotated ship images drops below 10\% and is alongside horse and truck images by far the lowest accuracy curve.