\section{Deep Neural Net - RegularNet}
The regular neural network is composed exclusively of regular and strided convolutional layers. While this architecture works well for relatively shallow networks, it becomes increasingly more difficult to train as the network depth increases.

This section will elaborate on the implementaiton of a RegularNet used for this project. For the implementation python 2.7 and Jupyter is used. The implementation of the RegularNet is from the github repository\footnote{\url{https://github.com/awjuliani/TF-Tutorials}}. 

The RegularNet implemented in the project consists of 34 layers, with an image as input layer. The first five layers in the neural network are normal convolutional layers with a zero padding of one, striding unit distance of one and feature mapping of 3x3. The convolutional layers are followed by a convolutional layer with a striding unit distance of two. The sixth layer functions as a pooling layer, since the output from the layer is an image of half the input size. The RegularNet consists of 25 convolutional layers, 5 pooling layers, 1 input layer, 1 flatten layer and a softmax classifier layer is appended to the end of the RegularNet. Adam is used as the activation function for the RegularNet, and normalization is used for regularization function. The creation of the RegularNet layers can be seen in listing \ref{lst:regularloop}.

\begin{lstlisting}[language=Python, label=lst:regularloop, caption=For loop that creates the layers in the RegularNet]
input_layer = tf.placeholder(shape=[None,32,32,3],dtype=tf.float32
,name='input')
label_layer = tf.placeholder(shape=[None],dtype=tf.int32)
label_oh = slim.layers.one_hot_encoding(label_layer,10)

layer1 = slim.conv2d(input_layer,64,[3,3],normalizer_fn=slim.batch_norm
,scope='conv_'+str(0))
for i in range(5):
for j in range(units_between_stride):
layer1 = slim.conv2d(layer1,64,[3,3],normalizer_fn=slim.batch_norm
,scope='conv_'+str((j+1) + (i*units_between_stride)))
layer1 = slim.conv2d(layer1,64,[3,3],stride=[2,2]
,normalizer_fn=slim.batch_norm,scope='conv_s_'+str(i))

top = slim.conv2d(layer1,10,[3,3],normalizer_fn=slim.batch_norm
,activation_fn=None,scope='conv_top')

output = slim.layers.softmax(slim.layers.flatten(top))
\end{lstlisting}

As seen in listing \ref{lst:regularloop} the function conv2d is called to create a convolution neuron. This function creates the convolution block with the internal layers and returns the output from the block. One neuron consists of 1 convolutional layer and 1 batch normalization block. Between the convolutional layer and the batch layer a ReLU activation function is added. The convolutional layer consists of 64 feature maps which each has 9 weights, so the convolutional layer outputs 64 new images for the relu function. The code for training and updating the model can be seen in \ref{lst:ConvLoss}.

\begin{lstlisting}[language=Python, label=lst:ConvLoss, caption= Implementation of learning rate type ADAM]
loss = tf.reduce_mean(-tf.reduce_sum(label_oh * tf.log(output) + 1e-10
, axis=[1]))
trainer = tf.train.AdamOptimizer(learning_rate=0.001)
update = trainer.minimize(loss)
\end{lstlisting}