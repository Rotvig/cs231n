{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the CIFAR10 dataset, go here: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "The training data is stored in 5 separate files, and we will alternate between them during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentCifar = 1\n",
    "cifar = unpickle('./cifar10/data_batch_1')\n",
    "cifarT = unpickle('./cifar10/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_layers = 25 #Specify how deep we want our network\n",
    "units_between_stride = total_layers / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "An implementation of a Dense Network as described in [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denseBlock(input_layer,i,j):\n",
    "    with tf.variable_scope(\"dense_unit\"+str(i)):\n",
    "        nodes = []\n",
    "        a = slim.conv2d(input_layer,64,[3,3],normalizer_fn=slim.batch_norm)\n",
    "        nodes.append(a)\n",
    "        for z in range(j):\n",
    "            b = slim.conv2d(tf.concat(nodes,3),64,[3,3],normalizer_fn=slim.batch_norm)\n",
    "            nodes.append(b)\n",
    "        return b\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_layer = tf.placeholder(shape=[None,32,32,3],dtype=tf.float32,name='input')\n",
    "label_layer = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "label_oh = slim.layers.one_hot_encoding(label_layer,10)\n",
    "\n",
    "layer1 = slim.conv2d(input_layer,64,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(0))\n",
    "for i in range(5):\n",
    "    layer1 = denseBlock(layer1,i,units_between_stride)\n",
    "    layer1 = slim.conv2d(layer1,64,[3,3],stride=[2,2],normalizer_fn=slim.batch_norm,scope='conv_s_'+str(i))\n",
    "    \n",
    "top = slim.conv2d(layer1,10,[3,3],normalizer_fn=slim.batch_norm,activation_fn=None,scope='conv_top')\n",
    "\n",
    "output = slim.layers.softmax(slim.layers.flatten(top))\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(label_oh * tf.log(output) + 1e-10, axis=[1]))\n",
    "trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "update = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the network graph\n",
    "We can call the Tensorflow Board to provide a graphical representation of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched CIFAR set to 2\n",
      "Step: 0 Loss: 2.66176 Accuracy: 0.0625\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 64\n",
    "currentCifar = 1\n",
    "total_steps = 20000\n",
    "l = []\n",
    "a = []\n",
    "aT = []\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "i = 0\n",
    "draw = range(10000)\n",
    "while i < total_steps:\n",
    "    if i % (10000/batch_size) != 0:\n",
    "        batch_index = np.random.choice(draw,size=batch_size,replace=False)\n",
    "    else:\n",
    "        draw = range(10000)\n",
    "        if currentCifar == 5:\n",
    "            currentCifar = 1\n",
    "            print \"Switched CIFAR set to \" + str(currentCifar)\n",
    "        else:\n",
    "            currentCifar = currentCifar + 1\n",
    "            print \"Switched CIFAR set to \" + str(currentCifar)\n",
    "        cifar = unpickle('./cifar10/data_batch_'+str(currentCifar))\n",
    "        batch_index = np.random.choice(draw,size=batch_size,replace=False)\n",
    "    x = cifar['data'][batch_index]\n",
    "    x = np.reshape(x,[batch_size,32,32,3],order='F')\n",
    "    x = (x/256.0)\n",
    "    x = (x - np.mean(x,axis=0)) / np.std(x,axis=0)\n",
    "    y = np.reshape(np.array(cifar['labels'])[batch_index],[batch_size,1])\n",
    "    _,lossA,yP,LO = sess.run([update,loss,output,label_oh],feed_dict={input_layer:x,label_layer:np.hstack(y)})\n",
    "    accuracy = np.sum(np.equal(np.hstack(y),np.argmax(yP,1)))/float(len(y))\n",
    "    l.append(lossA)\n",
    "    a.append(accuracy)\n",
    "    if i % 10 == 0: print \"Step: \" + str(i) + \" Loss: \" + str(lossA) + \" Accuracy: \" + str(accuracy)\n",
    "    if i % 100 == 0: \n",
    "        point = np.random.randint(0,10000-500)\n",
    "        xT = cifarT['data'][point:point+500]\n",
    "        xT = np.reshape(xT,[500,32,32,3],order='F')\n",
    "        xT = (xT/256.0)\n",
    "        xT = (xT - np.mean(xT,axis=0)) / np.std(xT,axis=0)\n",
    "        yT = np.reshape(np.array(cifarT['labels'])[point:point+500],[500])\n",
    "        lossT,yP = sess.run([loss,output],feed_dict={input_layer:xT,label_layer:yT})\n",
    "        accuracy = np.sum(np.equal(yT,np.argmax(yP,1)))/float(len(yT))\n",
    "        aT.append(accuracy)\n",
    "        print \"Test set accuracy: \" + str(accuracy)\n",
    "    i+= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(l) #Plot training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(a) #Plot training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(aT) #Plot test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d9b606f919c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Best test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.max(aT) #Best test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = 1\n",
    "imgNum = 20\n",
    "imgOrginal = cifarT['data'][imgNum]\n",
    "img = np.reshape(imgOrginal,[num,32,32,3],order='F')\n",
    "img = (img/256.0)\n",
    "img = (img - np.mean(img,axis=0)) / np.std(img,axis=0)\n",
    "label = np.reshape(np.array(cifarT['labels'])[20],[imgNum])\n",
    "\n",
    "lossT,yP = sess.run([loss,output],feed_dict={input_layer:img,label_layer:label})\n",
    "plt.imshow(np.reshape(imgOrginal,(32,32,3), order='F'))\n",
    "plt.show()\n",
    "    \n",
    "print 'Neural Network predicted:', yP\n",
    "print 'Real label is:', label\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
